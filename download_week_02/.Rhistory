# Don't modify this chunk of code, it is just installing and loading the DS705data package
if (!require(DS705data)){
if (!require(devtools)){
install.packages('devtools',repos="http://cran.rstudio.com/")
}
library(devtools)
install_github('DataScienceUWL/DS705data')
}
require(DS705data)
# load the HealthExam data set into memory
data(HealthExam)
# r defaults to a 7 by 7 figure (units?), use fig.width and fig.height to adjust
reps <- 1000
n <- 23
sampleStat <- numeric(reps) # initialize the vector
for (i in 1:reps){
sampleStat[i] <- mean( rexp(n) )
}
hist(sampleStat)
# This is a comment, change it and add your code below.
rexp(1000)
# This is a comment, change it and add your code below.
hist(rexp(1000))
# create a histogram of 1000 random samples of the exponential distribution.
hist(rexp(1000))
# create a histogram of 1000 random samples of the exponential distribution.
hist(rexp(1000))
# replace with your code
reps <- 1000
n <- 10
sampleStat <- numeric(reps) # initialize the vector
for (i in 1:reps){
sampleStat[i] <- mean( rexp(n) )
}
hist(sampleStat)
qqnorm(sampleStat)
# replace with your code
reps <- 1000
n <- 10
sampleStat <- numeric(reps) # initialize the vector
for (i in 1:reps){
sampleStat[i] <- mean( rexp(n) )
}
hist(sampleStat)
qqnorm(sampleStat)
qqline(sampleStat)
# replace with your code
par(mfrow=c(1,2),mar=c(2,1))
# replace with your code
par(mfrow=c(1,2),mar=c(2,2,1))
# replace with your code
par(mfrow=c(1,2))
reps <- 1000
n <- 10
sampleStat <- numeric(reps) # initialize the vector
for (i in 1:reps){
sampleStat[i] <- mean( rexp(n) )
}
hist(sampleStat)
qqnorm(sampleStat)
qqline(sampleStat)
# replace with your code
par(mfrow=c(1,2))
reps <- 1000
n <- 10
sampleStat <- numeric(reps) # initialize the vector
for (i in 1:reps){
sampleStat[i] <- mean( rexp(n) )
}
hist(sampleStat)
qqnorm(sampleStat)
qqline(sampleStat)
#reset to 1 plot
par(mfrow=c(1,1))
# replace with your code.
par(mfrow=c(1,2))
reps <- 1000
n <- 200
sampleStat <- numeric(reps) # initialize the vector
for (i in 1:reps){
sampleStat[i] <- mean( rexp(n) )
}
hist(sampleStat)
qqnorm(sampleStat)
qqline(sampleStat)
#reset to 1 plot
par(mfrow=c(1,1))
# replace with your code
sig <- (5.2-4.8)/4
(((1.96)^2)*((sig)^2))/.05
# replace with your code
sig <- (5.2-4.8)/4
(((1.96)^2)*((sig)^2))/(.05)
# replace with your code
sig <- (5.2-4.8)/4
print(sig)
(((1.96)^2)*((sig)^2))/(.05)
# replace with your code
sig <- (5.2-4.8)/4
print(sig)
(((1.96)^2)*((sig)^2))/(.05^2)
# replace with your code
sig <- (5.2-4.8)/4
(((1.96)^2)*((sig)^2))/(.05^2)
# replace with your code
sig <- (5.2-4.8)/4
round((((1.96)^2)*((sig)^2))/(.05^2))
# replace with your code
sig <- (5.2-4.8)/4
ceiling((((1.96)^2)*((sig)^2))/(.05^2))
library(swirl)
require(swirl)
swirl
swirl()
library(swirl)
install.packages('swirl')
library(swirl)
swirl()
install_course_github('DataScienceUWL','Statistical_Methods')
swirl()
?pnorm
swirl()
hist(wh)
t.test(wh, conf.level = .95)$conf.int
t.test(wh, conf.level = .99)$conf.int
tcrit <- qt(.975,20)
tcrit <- qt(.975,39)
xbar + c(-1,1) * tcrit * s/sqrt(n)
63.2 + c(-1,1) * tcrit * s/sqrt(n)
63.2 + c(-1,1) * tcrit * 2.74/sqrt(n)
63.2 + c(-1,1) * tcrit * 2.74/sqrt(40)
fakeData <- rnorm(40)
(fakeData - mean(fakeData))/sd(fakeData)
fakeData <- (fakeData - mean(fakeData))/sd(fakeData)
mean(fakeData)
sd(fakeData)
fakeData <- 2.74*fakeData + 63.2
mean(fakeData)
sd(fakeData)
t.test(fakeData, conf.level = .95)$conf.int
?scale
# replace with your code
fakeData <- rnorm(50)
fakeData <- (fakeData - mean(fakeData))/sd(fakeData)
fakeData <- .68*fakeData + 5.03
print(mean(fakeData))
print(sd(fakeData))
# replace with your code
fakeData <- rnorm(50)
fakeData <- (fakeData - mean(fakeData))/sd(fakeData)
fakeData <- .68*fakeData + 5.03
print(mean(fakeData))
print(sd(fakeData))
t.test(fakeData, conf.level = .95).$conf.int
# replace with your code
fakeData <- rnorm(50)
fakeData <- (fakeData - mean(fakeData))/sd(fakeData)
fakeData <- .68*fakeData + 5.03
print(mean(fakeData))
print(sd(fakeData))
t.test(fakeData, conf.level = .95)$conf.int
# load csv into data frame
df <- read.csv('ex5-29.TXT')
# put data for lead concentrations in vector lead
lead <- df$Lead
# delete the data frame since we no longer need it
rm(df)
# replace with your code
hist(lead)
# replace with your code
t.test(lead, conf.level = .80)$conf.int
?t.test
t.test(lead, mu = 30, alternative = less)
t.test(lead, mu = 30, alternative = "less")
t.test(lead, mu = 30, alternative = "greater")
# replace with your code
t.test(lead, conf.level = .80)$conf.int
lead_error = qt(.9,752) * sd(lead)/sqrt(753)
mean(lead) - lead_error
# replace with your code
t.test(lead, conf.level = .80)$conf.int
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
reps <- 10000
t_sim <- numeric(reps)
# generate bootstrapped sampling distribution
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
# build boostrapped "Studentized" t-inverval for mu
alpha <- .20
prbs <- c( 1-alpha/2, alpha/2 )
tcrit_est <- unname(quantile(t_sim, prob = prbs ))
t_ci_bootstrap <- xbar - tcrit_est*s/sqrt(n)
t_ci_bootstrap
# for comparison here is the t-interval from theory
t_ci_theory <- as.vector(t.test(chol)$conf.int)
t_ci_theory
# Compare the bootstrapped sampling distribution to the
# t-distribution from theory.  If the sample were from a normal distribution
# these would be in good agreement, instead we see some skewness in the smapling distribution ...
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
brks <- seq(min(t_sim),max(t_sim),length=50)
hist(t_sim,prob=TRUE,breaks=brks,main='',xlab='t',ylab='')
x0 <- seq(-4,4,length=400)
y0 <- dt(x0,df=39)
points(x0,y0,type='l',lwd=2,col='blue')
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
reps <- 10000
t_sim <- numeric(reps)
# generate bootstrapped sampling distribution
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
# build boostrapped "Studentized" t-inverval for mu
alpha <- .20
prbs <- c( 1-alpha/2, alpha/2 )
tcrit_est <- unname(quantile(t_sim, prob = prbs ))
t_ci_bootstrap <- xbar - tcrit_est*s/sqrt(n)
t_ci_bootstrap
# for comparison here is the t-interval from theory
t_ci_theory <- as.vector(t.test(chol)$conf.int)
t_ci_theory
# Compare the bootstrapped sampling distribution to the
# t-distribution from theory.  If the sample were from a normal distribution
# these would be in good agreement, instead we see some skewness in the smapling distribution ...
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
brks <- seq(min(t_sim),max(t_sim),length=50)
hist(t_sim,prob=TRUE,breaks=brks,main='',xlab='t',ylab='')
x0 <- seq(-4,4,length=400)
y0 <- dt(x0,df=(length(lead)-1))
points(x0,y0,type='l',lwd=2,col='blue')
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
reps <- 10000
t_sim <- numeric(reps)
# generate bootstrapped sampling distribution
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
# build boostrapped "Studentized" t-inverval for mu
alpha <- .20
prbs <- c( 1-alpha/2, alpha/2 )
tcrit_est <- unname(quantile(t_sim, prob = prbs ))
t_ci_bootstrap <- xbar - tcrit_est*s/sqrt(n)
t_ci_bootstrap
# for comparison here is the t-interval from theory
t_ci_theory <- as.vector(t.test(chol)$conf.int)
t_ci_theory
# Compare the bootstrapped sampling distribution to the
# t-distribution from theory.  If the sample were from a normal distribution
# these would be in good agreement, instead we see some skewness in the smapling distribution ...
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
brks <- seq(min(t_sim),max(t_sim),length=50)
hist(t_sim,prob=TRUE,breaks=brks,main='',xlab='t',ylab='')
x0 <- seq(-4,4,length=400)
#y0 <- dt(x0,df=(length(lead)-1))
points(x0,type='l',lwd=2,col='blue')
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
reps <- 10000
t_sim <- numeric(reps)
# generate bootstrapped sampling distribution
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
# build boostrapped "Studentized" t-inverval for mu
alpha <- .20
prbs <- c( 1-alpha/2, alpha/2 )
tcrit_est <- unname(quantile(t_sim, prob = prbs ))
t_ci_bootstrap <- xbar - tcrit_est*s/sqrt(n)
t_ci_bootstrap
# for comparison here is the t-interval from theory
t_ci_theory <- as.vector(t.test(chol)$conf.int)
t_ci_theory
# Compare the bootstrapped sampling distribution to the
# t-distribution from theory.  If the sample were from a normal distribution
# these would be in good agreement, instead we see some skewness in the smapling distribution ...
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
brks <- seq(min(t_sim),max(t_sim),length=50)
hist(t_sim,prob=TRUE,breaks=brks,main='',xlab='t',ylab='')
x0 <- seq(-4,4,length=400)
#y0 <- dt(x0,df=(length(lead)-1))
points(x0,y0,type='l',lwd=2,col='blue')
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
reps <- 10000
t_sim <- numeric(reps)
# generate bootstrapped sampling distribution
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
# build boostrapped "Studentized" t-inverval for mu
alpha <- .20
prbs <- c( 1-alpha/2, alpha/2 )
tcrit_est <- unname(quantile(t_sim, prob = prbs ))
t_ci_bootstrap <- xbar - tcrit_est*s/sqrt(n)
t_ci_bootstrap
# for comparison here is the t-interval from theory
t_ci_theory <- as.vector(t.test(chol)$conf.int)
t_ci_theory
# Compare the bootstrapped sampling distribution to the
# t-distribution from theory.  If the sample were from a normal distribution
# these would be in good agreement, instead we see some skewness in the smapling distribution ...
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
brks <- seq(min(t_sim),max(t_sim),length=50)
hist(t_sim,prob=TRUE,breaks=brks,main='',xlab='t',ylab='')
x0 <- seq(-4,4,length=400)
y0 <- dt(x0,df=(length(lead)-1))
points(x0,y0,type='l',lwd=2,col='blue')
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
mu0 <- 320
t0 <- (xbar-mu0)/(s/sqrt(n))
p0 = pt(t0,df = n-1, lower.tail=FALSE)
reps <- 10000
t_sim <- numeric(reps)
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
p1 <- signif(sum(t_sim>t0)/reps,3)
p1
xpts <- seq(min(t_sim),max(t_sim),length=400)
ypts <- dt(xpts,df=n-1)
brks <- seq(min(t_sim),max(t_sim),length=50)
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
hist( t_sim, prob=TRUE, breaks=brks,main='',xlab='t',ylab='')
points(xpts,ypts,type = 'l',col='blue',lwd=2)
points(c(t0,t0),c(0,dt(t0,df=39)),type='l',col='red',lwd=2)
text(2.2,.2,bquote(P%~~%.(p1)))
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
reps <- 10000
t_sim <- numeric(reps)
# generate bootstrapped sampling distribution
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
# build boostrapped "Studentized" t-inverval for mu
alpha <- .20
prbs <- c( 1-alpha/2, alpha/2 )
tcrit_est <- unname(quantile(t_sim, prob = prbs ))
t_ci_bootstrap <- xbar - tcrit_est*s/sqrt(n)
t_ci_bootstrap
# for comparison here is the t-interval from theory
t_ci_theory <- as.vector(t.test(chol)$conf.int)
t_ci_theory
# Compare the bootstrapped sampling distribution to the
# t-distribution from theory.  If the sample were from a normal distribution
# these would be in good agreement, instead we see some skewness in the smapling distribution ...
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
brks <- seq(min(t_sim),max(t_sim),length=50)
hist(t_sim,prob=TRUE,breaks=brks,main='',xlab='t',ylab='')
x0 <- seq(-4,4,length=400)
y0 <- dt(x0,df=n-1))
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
reps <- 10000
t_sim <- numeric(reps)
# generate bootstrapped sampling distribution
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
# build boostrapped "Studentized" t-inverval for mu
alpha <- .20
prbs <- c( 1-alpha/2, alpha/2 )
tcrit_est <- unname(quantile(t_sim, prob = prbs ))
t_ci_bootstrap <- xbar - tcrit_est*s/sqrt(n)
t_ci_bootstrap
# for comparison here is the t-interval from theory
t_ci_theory <- as.vector(t.test(chol)$conf.int)
t_ci_theory
# Compare the bootstrapped sampling distribution to the
# t-distribution from theory.  If the sample were from a normal distribution
# these would be in good agreement, instead we see some skewness in the smapling distribution ...
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
brks <- seq(min(t_sim),max(t_sim),length=50)
hist(t_sim,prob=TRUE,breaks=brks,main='',xlab='t',ylab='')
x0 <- seq(-4,4,length=400)
y0 <- dt(x0,df=n-1)
points(x0,y0,type='l',lwd=2,col='blue')
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
mu0 <- 30
t0 <- (xbar-mu0)/(s/sqrt(n))
p0 = pt(t0,df = n-1, lower.tail=FALSE)
reps <- 10000
t_sim <- numeric(reps)
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
p1 <- signif(sum(t_sim>t0)/reps,3)
p1
xpts <- seq(min(t_sim),max(t_sim),length=400)
ypts <- dt(xpts,df=n-1)
brks <- seq(min(t_sim),max(t_sim),length=50)
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
hist( t_sim, prob=TRUE, breaks=brks,main='',xlab='t',ylab='')
points(xpts,ypts,type = 'l',col='blue',lwd=2)
points(c(t0,t0),c(0,dt(t0,df=39)),type='l',col='red',lwd=2)
text(2.2,.2,bquote(P%~~%.(p1)))
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
mu0 <- 30
t0 <- (xbar-mu0)/(s/sqrt(n))
p0 = pt(t0,df = n-1, lower.tail=FALSE)
reps <- 10000
t_sim <- numeric(reps)
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
p1 <- signif(sum(t_sim>t0)/reps,3)
p1
xpts <- seq(min(t_sim),max(t_sim),length=400)
ypts <- dt(xpts,df=n-1)
brks <- seq(min(t_sim),max(t_sim),length=50)
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
hist( t_sim, prob=TRUE, breaks=brks,main='',xlab='t',ylab='')
points(xpts,ypts,type = 'l',col='blue',lwd=2)
points(c(t0,t0),c(0,dt(t0,df=n-1)),type='l',col='red',lwd=2)
text(2.2,.2,bquote(P%~~%.(p1)))
chol <- lead
n <- length(chol)
xbar <- mean(chol)
s <- sd(chol)
mu0 <- 30
t0 <- (xbar-mu0)/(s/sqrt(n))
p0 = pt(t0,df = n-1, lower.tail=FALSE)
reps <- 10000
t_sim <- numeric(reps)
for (i in 1:reps){
x <- sample(chol,n,replace=TRUE)
t_sim[i] <- (mean(x)-xbar)/(sd(x)/sqrt(n))
}
p1 <- signif(sum(t_sim>t0)/reps,3)
p1
xpts <- seq(min(t_sim),max(t_sim),length=400)
ypts <- dt(xpts,df=n-1)
brks <- seq(min(t_sim),max(t_sim),length=50)
par(mar=(c(4,.5,0,.5)),yaxs="i",bty="l",xaxs="i",yaxt="n")
hist( t_sim, prob=TRUE, breaks=brks,main='',xlab='t',ylab='')
points(xpts,ypts,type = 'l',col='blue',lwd=2)
points(c(t0,t0),c(0,dt(t0,df=n-1)),type='l',col='red',lwd=2)
text(2.2,.2,bquote(P%~~%.(p1)))
# your code goes here
power.t.test(n = n,delta = 10,sd = s, sig.level = .1)
# your code goes here
power.t.test(n = n,delta = 10,sd = s, sig.level = .1, type = "one.sample", alternative = "one.sided")
power.t.test(power = .9,delta = 10,sd = s, type = "one.sample", alternative = "one.sided")$n
power.t.test(power = .9,delta = 10,sd = s, sig.level = .1, type = "one.sample", alternative = "one.sided")
power.t.test(power = .9,delta = 10,sd = s, sig.level = .1, type = "one.sample", alternative = "one.sided")$n
power.t.test(power = .9,delta = 10,sd = 37.1, sig.level = .1, type = "one.sample", alternative = "one.sided")$n
